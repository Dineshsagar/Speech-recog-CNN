{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwwaTdZ8894j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import librosa   #\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import wavfile #for audio processing\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSGWSngs8-pG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "6f50b436-7c75-41c6-ff50-4dc895811399"
      },
      "source": [
        "# created by loading an external audio file. couldnt use google recog.\n",
        "train_audio_path = '../input/tensorflow-speech-recognition-challenge/train/audio/'\n",
        "samples, sample_rate = librosa.load(train_audio_path+'yes/0a7c2a8d_nohash_0.wav', sr = 16000)\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.set_title('Raw wave of ' + '../input/train/audio/yes/0a7c2a8d_nohash_0.wav')\n",
        "ax1.set_xlabel('time')\n",
        "ax1.set_ylabel('Amplitude')\n",
        "ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-695e34998cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_audio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/tensorflow-speech-recognition-challenge/train/audio/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_audio_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'yes/0a7c2a8d_nohash_0.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input/tensorflow-speech-recognition-challenge/train/audio/yes/0a7c2a8d_nohash_0.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5d4rpF9WkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_audio_path = '../input/tensorflow-speech-recognition-challenge/train/audio/'\n",
        "\n",
        "all_wave = []\n",
        "all_label = []\n",
        "for label in labels:\n",
        "    print(label)\n",
        "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
        "    for wav in waves:\n",
        "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
        "        samples = librosa.resample(samples, sample_rate, 8000)\n",
        "        if(len(samples)== 8000) : \n",
        "            all_wave.append(samples)\n",
        "            all_label.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYfdjYsmA-cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ltpqe7e9eGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y=le.fit_transform(all_label)\n",
        "classes= list(le.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uW1Wg9b9h_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y=np_utils.to_categorical(y, num_classes=len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t162Piq9lTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshaping\n",
        "\n",
        "\n",
        "all_wave = np.array(all_wave).reshape(-1,8000,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktw7WU8o9rm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PcFsCij9zRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "inputs = Input(shape=(8000,1))\n",
        "\n",
        "#First Conv1D layer\n",
        "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Second Conv1D layer\n",
        "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Third Conv1D layer\n",
        "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Fourth Conv1D layer\n",
        "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Flatten layer\n",
        "conv = Flatten()(conv)\n",
        "\n",
        "#Dense Layer 1\n",
        "conv = Dense(256, activation='relu')(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Dense Layer 2\n",
        "conv = Dense(128, activation='relu')(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "outputs = Dense(len(labels), activation='softmax')(conv)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m7561nN9-iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWyPGzRz9_Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
        "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#to stop epoch at correct time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_gGSKm4-Gis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(x_tr, y_tr ,epochs=100, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faG0nlC3-Key",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj467ONQA_ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('best_model.hdf5')\n",
        "\n",
        "#Actual partt tp take input from user. and it stores on file in.wav format\n",
        "\n",
        "import sounddevice as sd\n",
        "import soundfile as sf\n",
        "\n",
        "samplerate = 16000  \n",
        "duration = 1 # seconds\n",
        "filename = 'yes.wav'\n",
        "print(\"start\")\n",
        "mydata = sd.rec(int(samplerate * duration), samplerate=samplerate,\n",
        "    channels=1, blocking=True)\n",
        "print(\"end\")\n",
        "sd.wait()\n",
        "sf.write(filename, mydata, samplerate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XievwPo-BbcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading the voice commands\n",
        "samples, sample_rate = librosa.load(filepath + '/' + 'stop.wav', sr = 16000)\n",
        "samples = librosa.resample(samples, sample_rate, 8000)\n",
        "ipd.Audio(samples,rate=8000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8ni6YwBdHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#converting voice commands to text\n",
        "predict(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch-PeEkOA_ZY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}